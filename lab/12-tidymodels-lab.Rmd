---
title: "Modelling with `tidymodels`"
subtitle: "Practice Materials"
author: "Franke Tetteroo, Linus Hagemann & Sofiya Berdiyeva"
date: "28.10.2024"
output: 
    rmdformats::robobook:
    toc: TRUE
    df_print: paged
    number_sections: FALSE
    highlight: tango
    toc_depth: 3
    toc_float: true
    self_contained: false
---

```{=html}
<style>
.h1,h2,h3 {
color:#2f1a61;
}

.subtitle, section.normal {
color:#291854;
}

.title {
color:#cc0065;
}

.nav-pills>li>a{
color: #2f1a61;
}

.nav-pills>li.active>a, .nav-pills>li.active>a:hover, .nav-pills>li.active>a:focus {
color: #fff;
background-color: #2f1a61;
}

.nav-tabs>li>a{
color: #2f1a61;
}

.nav-tabs>li.active>a, .nav-tabs>li.active>a:hover, .nav-tabs>li.active>a:focus {
color: #fff;
background-color: #2f1a61;
}

</style>
```
```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, message = FALSE, warning = FALSE)
```

# Example.

1. Loading and transforming the data with recipe


2. Sampling & bootstrapping


3. Model creation


4. Evaluation



```{r eval = FALSE}
# parsnip model ALWAYS returns the results as a data frame 
predictions <- bind_cols(
  select(auto_test, mpg),
  predict(model, auto_test)
)

# And here comes yardstick
# When "truth" is a factor: accuracy and the Kappa
# When "truth" is numeric: rmse, rsq and mae.

# Estimate one or more common performance estimates depending on the class of truth 
metrics(predictions, truth = older, estimate = .pred)

# Regression metrics
reg_metrics <- metric_set(huber_loss, iic, mape, mase)

# The returned function has the same arguments as metrics()
reg_metric(predictions, truth = mpg, estimate = .pred)

```


# Exercise.

1. Loading and transforming the data with recipe


2. Sampling & bootstrapping


3. Model creation


4. Evaluation

```{r eval = FALSE}
# TO BE CORRECTED!!!

predictions_lm <- bind_cols(
 select(auto_test, mpg),
 predict(linreg_reg_model, auto_test)
)

# One or more common performance estimates
# metrics(data= YOUR CODE, truth = YOUR CODE, estimate = YOUR CODE)

# Calculate symmetric mean absolute percentage error
# Who has the lowest value?

# Answer: smape(predictions_lm, truth = mpg, estimate = .pred)

# OR

# Calculate the coefficient of determination (the traditional one)
# Who has the highest value?

# Answer: rsq_trad(predictions_lm, truth = mpg, estimate = .pred)
```




## demo on how to make tabs! {.tabset}

#### test tabbing
including `{.tabset}` next to a heading will make all subheadings (one level presumably) into tabs

#### give me tabs!
to cancel it just put a higher order heading

### content after tabs

# Sources

Include Sources Here
