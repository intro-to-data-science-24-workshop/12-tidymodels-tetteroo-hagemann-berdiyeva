<!DOCTYPE html>
<html lang="" xml:lang="">
  <head>
    <title>Introduction to Data Science - Workshop 2024</title>
    <meta charset="utf-8" />
    <meta name="author" content="Franka Tetteroo, Linus Hagemann &amp; Sofiya Berdiyeva" />
    <script src="libs/header-attrs-2.28/header-attrs.js"></script>
    <link href="libs/remark-css-0.0.1/default.css" rel="stylesheet" />
    <link href="libs/remark-css-0.0.1/metropolis.css" rel="stylesheet" />
    <link href="libs/remark-css-0.0.1/metropolis-fonts.css" rel="stylesheet" />
  </head>
  <body>
    <textarea id="source">
class: center, middle, inverse, title-slide

.title[
# Introduction to Data Science - Workshop 2024
]
.subtitle[
## Session 12: Modelling with <code>tidymodels</code>
]
.author[
### Franka Tetteroo, Linus Hagemann &amp; Sofiya Berdiyeva
]

---



&lt;style type="text/css"&gt;
@media print { # print out incremental slides; see https://stackoverflow.com/questions/56373198/get-xaringan-incremental-animations-to-print-to-pdf/56374619#56374619
  .has-continuation {
    display: block !important;
  }
}
&lt;/style&gt;


# **Rsample** package
.pull-left[
Useful to split your data into testing and training subsets:

Why do we care? 
- Having multiple splits allows us to construct and compare different models with different (combinations of) parameters.
- The final model is only used on the test set once, so we want to make sure that the final model is the best way of explaining the data.
  - If we run multiple models on the test set, we start to optimise our model to the test set instead of focusing on the model's general ability to explain the dataset. 
]

.pull-right[
&lt;div align="center"&gt;
&lt;img src="pics/Datasplittingscheme.png" height=300&gt;
&lt;/div&gt;
]
---
# **Different ways of splitting your dataset**


.pull-left[
- Initial split (training vs testing) --&gt; initial_split(dataset, prop = 0.x, strata = desired column)
- Cross validation and V-fold
- Bootstraps
- Rolling forecast
]

.pull-right[
&lt;div align="center"&gt;
&lt;img src="pics/One_Does_Not_Simply_Split.png" height=300&gt;
&lt;/div&gt;
]
---
# Cross validation and V-fold


.pull-left[
- The data is split into v-sets of data called folds of equal size.  
- Function: vfold_cv(dataset, v = x)
  - E.g. x = 3, the data is split in three different ways with 2/3 in analysis en 1/3 is assessment.
  - The default is set to 10, this is still manageable but enough to produce robust results. 
- Output is a tibble containing lists, each list contains information on how the data is split.
  - We can unpack the first column to get our analysis and assessment set. 
- For more information and variants of cross validation check out: [Tidy Modelling with R Ch 10](https://www.tmwr.org/resampling).
]

.pull-right[
&lt;div align="center"&gt;
&lt;img src="pics/V-fold.png" height=300&gt;
&lt;/div&gt;
]
---
# Bootstrapping

.pull-left[
- Analysis sets are sampled from training dataset **with** replacement.
  - Has the same size as the training dataset
- Analysis vs Assessment (Out-of-the bag) split
  - Why does the assessment set differ in size?
- Function: bootstraps(dataset, times = x).


.pull-right[
&lt;div align="center"&gt;
&lt;img src="pics/Bootstrap.png" height=300&gt;
&lt;/div&gt;
]
---
# Rolling Forecasting Origing Resampling
.pull-left[
- If our dataset has a temporal component, simply random sampling can disrupt the model in estimating patterns.
  - Solution: fit_resamples(formula, resamples, ...)
- We set the size of the analysis and assessment sets. The first sample follows this division, the second iteration takes the same data size but shifts by a specified number. 
- Alternatively we don't have to shift by one day but also by one week or more. 
]

.pull-right[
&lt;div align="center"&gt;
&lt;img src="pics/RollingForecasting.png" height=300&gt;
&lt;/div&gt;
]
---
# Preprocessing and Feature Engineering

- Data needs to adhere to some model-specific rules and assumptions

&gt; __Feature Engineering__
&gt; The process of transforming raw data into features well suited-for modelling.

- What does this entail?
    - removing NA's -&gt; how to deal with them? Throw data away? Impute with mean/median/...?
    - Transform numeric values (`log`, `sqrt`,...)
    - Rescale numeric values
    - deal with nominal/string values
    
---
# Pre-processing with recipes

- While all of this can be coded by hand, `recipes` make our life's easier by providing the necessary operations in a standardized way
- familiar to `tidyverse` users and compatible with `dplyr` 
```r
rec &lt;- recipe(predictor ~ ., data = training_data) %&gt;%
      step_corr(all_predictors()) %&gt;% # remove features with high correlation between them
      step_string2factor(all_string_predictors()) %&gt;%
      step_impute_mean(all_numeric_predictors()) %&gt;%
      step_mutate(&lt;dplyr call&gt;)
```
--
- can be reused easily, as we can rely on roles and not specific variable names
--
&lt;br&gt;
- Use
    - `prep()` to calculate pre-processing parameters (e.g., mean to impute)
    - `bake()` to apply the pre-processing steps to the actual data
---
# Modelling in R

- Many different models to choose from
    - Type of model to use is an important decision, which needs to grounded __in theory__
- For each type of model, multiple implementations are available
- Consider these examples for linear regression models:
---
# Modelling in R

- `stat::lm()`
```r
lm(formula, data, [...], ...)
```
--

- `glmnet::glm()`
```r
glmnet(x, y, [...], standardize = TRUE, intercept = TRUE, ...)
```
--

- `sparklyr::ml_linear_regression()`
```r
ml_linear_regression(x, formula = NULL, fit_intercept = TRUE, [...], standardization = TRUE, [...], ...)
```
---
# Modelling in R
.pull-left[
- Syntax differs
    - in argument order
    - in argument names
    - (in output formatting/reporting -&gt; __later__)
    
&lt;img src="pics/so_many_syntaxes.jpg" height=300&gt;
]
--
.pull-right[
- Parsnip to the rescue!

&lt;img src="pics/parsnip_logo.png" height=300&gt;
]
---
# parsnip

- package that aims to unify signatures of different models in `R`
- one familiar approach to **many different types of models**
    - [Searchable list](https://www.tidymodels.org/find/parsnip/) of all models available through `parsnip`

```
  linear_reg() %&gt;% 
  set_engine("lm") %&gt;% 
  fit(dependent ~ pred_one + pred_two, data = data)
```
--
&lt;br&gt;
- `linear_reg()`, `decision_tree()`, `logistic_reg()`, ...
- `set_engine` to specify which implementation to use
- unified way of fitting a model to a dataset: `fit()`
- unified way of predicting the outcome on a dataset: `predict(fitted_model, data)`

---
# **yardstick** package

Contains tools for computing statistical performance metrics

- Consistent Syntax 
- Wide Range of Metrics (43)
- Grouped calculations (e.g. `demographic_parity()`)
- Customization (e.g. `new-metric()` see more on [custom performance metrics](https://www.tidymodels.org/learn/develop/metrics/))

`metrics(data, truth, estimate, ..., na_rm = TRUE, options = list())`

[Manual](https://cran.r-project.org/web/packages/yardstick/yardstick.pdf)

&lt;div align="center"&gt;
&lt;img src="pics/Metrics_meme.png" height=300&gt;
&lt;/div&gt;


---
# Classification metrics

Measuring the accuracy in prediction of categories

| Function         | Name                              | Interpretation                   |
|------------------|-----------------------------------|----------------------------------|
| accuracy()       | Accuracy                          | 0 &lt; x &lt; 1, the higher the better |
| f_meas()         | F-measure                         | 0 &lt; x &lt; 1, the higher the better |
| kap()            | Cohen's Kappa                     | -1 &lt; x &lt; 1, the closer to 1 the better |
| mcc()            | Matthews Correlation Coefficient   | -1 &lt; x &lt; 1, the closer to 1 the better |
| npv()            | Negative Predictive Value         | 0 &lt; x &lt; 1, the higher the better |
| ppv()            | Positive Predictive Value         | 0 &lt; x &lt; 1, the higher the better |
| precision()          | Precision                   | 0 &lt; x &lt; 1, the higher the better   |
| recall()             | Recall                      | 0 &lt; x &lt; 1, the higher the better   |
| spec()               | Specificity                 | 0 &lt; x &lt; 1, the higher the better   |
| roc_auc()            | Area Under ROC Curve         | 0.5 &lt; x &lt; 1, the higher the better |
| pr_auc()             | Area Under PR Curve          | 0 &lt; x &lt; 1, the higher the better   |


---
# Regression metrics

Measuring the accuracy in prediction of continuous numeric values

| Function              | Name                         | Interpretation                     |
|-----------------------|------------------------------|------------------------------------|
| ccc()                 | Concordance Correlation Coefficient | -1 &lt; x &lt; 1, the closer to 1 the better |
| iic()                 | Index of Ideality of Correlation | 0 &lt; x &lt; 1, the higher the better    |
| **mae()**                 | Mean Absolute Error           | 0 &lt; x &lt; `\(\infty\)`, the lower the better     |
| mape()                | Mean Absolute Percentage Error | 0 &lt; x &lt; `\(\infty\)`, the lower the better    |
| msd()                 | Mean Squared Deviation        | 0 &lt; x &lt; `\(\infty\)`, the lower the better     |
| poisson_log_loss()    | Poisson Log Loss              | 0 &lt; x &lt; `\(\infty\)`, the lower the better     |
| **rmse()**                | Root Mean Squared Error       | 0 &lt; x &lt; `\(\infty\)`, the lower the better     |
| rpd()                 | Relative Percent Difference    | 0 &lt; x &lt; 1, the lower the better     |
| **rsq_trad()**            | Traditional R-squared         | 0 &lt; x &lt; 1, the closer to 1 the better |
| smape()               | Symmetric Mean Absolute Percentage Error | 0 &lt; x &lt; 1, the lower the better |

---
# Further Ressources

- ð Website of the [`tidymodels`](https://www.tidymodels.org/) package, including documentation and guides
    - `tidymodels` consists of many more packages than we could cover in this session!
- ð [Tidy Modelling with R](https://www.tmwr.org/)
- ðº [Get started with tidymodels and classification of penguin data by Julia Silge](Get started with tidymodels and classification of penguin data)
- ðº [tidymodels: Adventures in Rewriting a Modeling Pipeline - posit::conf(2023)](https://www.youtube.com/watch?v=R7XNqcCZnLg)
    </textarea>
<style data-target="print-only">@media screen {.remark-slide-container{display:block;}.remark-slide-scaler{box-shadow:none;}}</style>
<script src="https://remarkjs.com/downloads/remark-latest.min.js"></script>
<script>var slideshow = remark.create({
"highlightStyle": "github",
"highlightLines": true,
"countIncrementalSlides": false,
"ratio": "16:9",
"hash": true
});
if (window.HTMLWidgets) slideshow.on('afterShowSlide', function (slide) {
  window.dispatchEvent(new Event('resize'));
});
(function(d) {
  var s = d.createElement("style"), r = d.querySelector(".remark-slide-scaler");
  if (!r) return;
  s.type = "text/css"; s.innerHTML = "@page {size: " + r.style.width + " " + r.style.height +"; }";
  d.head.appendChild(s);
})(document);

(function(d) {
  var el = d.getElementsByClassName("remark-slides-area");
  if (!el) return;
  var slide, slides = slideshow.getSlides(), els = el[0].children;
  for (var i = 1; i < slides.length; i++) {
    slide = slides[i];
    if (slide.properties.continued === "true" || slide.properties.count === "false") {
      els[i - 1].className += ' has-continuation';
    }
  }
  var s = d.createElement("style");
  s.type = "text/css"; s.innerHTML = "@media print { .has-continuation { display: none; } }";
  d.head.appendChild(s);
})(document);
// delete the temporary CSS (for displaying all slides initially) when the user
// starts to view slides
(function() {
  var deleted = false;
  slideshow.on('beforeShowSlide', function(slide) {
    if (deleted) return;
    var sheets = document.styleSheets, node;
    for (var i = 0; i < sheets.length; i++) {
      node = sheets[i].ownerNode;
      if (node.dataset["target"] !== "print-only") continue;
      node.parentNode.removeChild(node);
    }
    deleted = true;
  });
})();
// add `data-at-shortcutkeys` attribute to <body> to resolve conflicts with JAWS
// screen reader (see PR #262)
(function(d) {
  let res = {};
  d.querySelectorAll('.remark-help-content table tr').forEach(tr => {
    const t = tr.querySelector('td:nth-child(2)').innerText;
    tr.querySelectorAll('td:first-child .key').forEach(key => {
      const k = key.innerText;
      if (/^[a-z]$/.test(k)) res[k] = t;  // must be a single letter (key)
    });
  });
  d.body.setAttribute('data-at-shortcutkeys', JSON.stringify(res));
})(document);
(function() {
  "use strict"
  // Replace <script> tags in slides area to make them executable
  var scripts = document.querySelectorAll(
    '.remark-slides-area .remark-slide-container script'
  );
  if (!scripts.length) return;
  for (var i = 0; i < scripts.length; i++) {
    var s = document.createElement('script');
    var code = document.createTextNode(scripts[i].textContent);
    s.appendChild(code);
    var scriptAttrs = scripts[i].attributes;
    for (var j = 0; j < scriptAttrs.length; j++) {
      s.setAttribute(scriptAttrs[j].name, scriptAttrs[j].value);
    }
    scripts[i].parentElement.replaceChild(s, scripts[i]);
  }
})();
(function() {
  var links = document.getElementsByTagName('a');
  for (var i = 0; i < links.length; i++) {
    if (/^(https?:)?\/\//.test(links[i].getAttribute('href'))) {
      links[i].target = '_blank';
    }
  }
})();
// adds .remark-code-has-line-highlighted class to <pre> parent elements
// of code chunks containing highlighted lines with class .remark-code-line-highlighted
(function(d) {
  const hlines = d.querySelectorAll('.remark-code-line-highlighted');
  const preParents = [];
  const findPreParent = function(line, p = 0) {
    if (p > 1) return null; // traverse up no further than grandparent
    const el = line.parentElement;
    return el.tagName === "PRE" ? el : findPreParent(el, ++p);
  };

  for (let line of hlines) {
    let pre = findPreParent(line);
    if (pre && !preParents.includes(pre)) preParents.push(pre);
  }
  preParents.forEach(p => p.classList.add("remark-code-has-line-highlighted"));
})(document);</script>

<script>
slideshow._releaseMath = function(el) {
  var i, text, code, codes = el.getElementsByTagName('code');
  for (i = 0; i < codes.length;) {
    code = codes[i];
    if (code.parentNode.tagName !== 'PRE' && code.childElementCount === 0) {
      text = code.textContent;
      if (/^\\\((.|\s)+\\\)$/.test(text) || /^\\\[(.|\s)+\\\]$/.test(text) ||
          /^\$\$(.|\s)+\$\$$/.test(text) ||
          /^\\begin\{([^}]+)\}(.|\s)+\\end\{[^}]+\}$/.test(text)) {
        code.outerHTML = code.innerHTML;  // remove <code></code>
        continue;
      }
    }
    i++;
  }
};
slideshow._releaseMath(document);
</script>
<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
(function () {
  var script = document.createElement('script');
  script.type = 'text/javascript';
  script.src  = 'https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML';
  if (location.protocol !== 'file:' && /^https?:/.test(script.src))
    script.src  = script.src.replace(/^https?:/, '');
  document.getElementsByTagName('head')[0].appendChild(script);
})();
</script>
  </body>
</html>
